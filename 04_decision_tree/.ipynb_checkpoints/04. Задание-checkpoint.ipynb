{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbdfd1e",
   "metadata": {},
   "source": [
    "# **Деревья решений**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf3325",
   "metadata": {},
   "source": [
    "## **Подготовка для работы в Google Colab или Kaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44d38e",
   "metadata": {},
   "source": [
    "#### Код для подключения Google Drive в Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50e760",
   "metadata": {},
   "source": [
    "#### Код для получения пути к файлам в Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a9d17",
   "metadata": {},
   "source": [
    "#### Код для установки библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56799f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.26.4 pandas==2.1.4 scikit-learn==1.7.0 matplotlib==3.8.0 graphviz == 0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc68002",
   "metadata": {},
   "source": [
    "## **Важная информация**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b6af3",
   "metadata": {},
   "source": [
    "**Для правильного воспроизведения результатов** решения задач:\n",
    "\n",
    "* Рекомендуется придерживаться имеющего в заданиях кода в исходной последовательности. Для этого при решении задач **восстановите недостающие фрагменты кода, которые отмечены символом** `...` (Ellipsis).\n",
    "\n",
    "* Если класс, функция или метод предусматривает параметр random_state, всегда указывайте **random_state=RANDOM_STATE**.\n",
    "\n",
    "* Для всех параметров (кроме random_state) класса, функции или метода **используйте значения по умолчанию, если иное не указано в задании**.\n",
    "\n",
    "**Если скорость обучения слишком низкая**, рекомендуется следующее:\n",
    "\n",
    "* В модели или/и GridSearchCV поменяйте значение параметра n_jobs, который отвечает за параллелизм вычислений.\n",
    "\n",
    "* Воспользуйтесь вычислительными ресурсами Google Colab или Kaggle.\n",
    "\n",
    "***Использовать GPU не рекомендуется, поскольку результаты обучения некоторых моделей могут отличаться на CPU и GPU.***\n",
    "\n",
    "После выполнения каждого задания **ответьте на вопросы в тесте.**\n",
    "\n",
    "**ВНИМАНИЕ:** **После каждого нового запуска ноутбука** перед тем, как приступить к выполнению заданий, проверьте настройку виртуального окружения, выполнив код в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44397273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для проверки настройки виртуального окружения\n",
    "\n",
    "import sys\n",
    "from importlib.metadata import version\n",
    "\n",
    "required = {\n",
    "    'python': '3.11.x',\n",
    "    'numpy': '1.26.4',\n",
    "    'pandas': '2.1.4',\n",
    "    'scikit-learn': '1.7.0',\n",
    "    'matplotlib': '3.8.0',\n",
    "    'graphviz': '0.21'\n",
    "}\n",
    "\n",
    "print(f'{\"Компонент\":<15} | {\"Требуется\":<12} | {\"Установлено\":<12} | {\"Соответствие\"}')\n",
    "print('-' * 62)\n",
    "\n",
    "environment_ok = True\n",
    "for lib, req_ver in required.items():\n",
    "    try:\n",
    "        if lib == 'python':\n",
    "            inst_ver = sys.version.split()[0]\n",
    "            status = '✓' if sys.version_info.major == 3 and sys.version_info.minor == 11 else f'x (требуется {req_ver})'\n",
    "        else:\n",
    "            inst_ver = version(lib)\n",
    "            if inst_ver == req_ver:\n",
    "                status = '✓'\n",
    "            else:\n",
    "                environment_ok = False\n",
    "                status = f'x (требуется {req_ver})'\n",
    "    except:\n",
    "        environment_ok = False\n",
    "        inst_ver = '-'\n",
    "        status = 'x (не установлена)'\n",
    "    print(f'{lib:<15} | {req_ver:<12} | {inst_ver:<12} | {status}')\n",
    "\n",
    "print('\\nРезультат проверки: ', \n",
    "      '✓\\nВсе версии соответствуют требованиям' \n",
    "      if environment_ok else \n",
    "      'x\\nВНИМАНИЕ: Версии некоторых компонентов не соответствуют требованиям!\\n'\n",
    "      'Для решения проблемы обратитесь к инструкции по настройке виртуального окружения')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e020f4f",
   "metadata": {},
   "source": [
    "## **Импорт библиотек и вспомогательные функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9637a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9988fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Выводит отчёт с основными метриками качества регрессии.\n",
    "    Округляет до 4-х знаков после запятой и выводит значения R2 (коэффициент детерминации), RMSE (среднеквадратичная ошибка) и MAPE (средняя абсолютная процентная ошибка) для оценки качества предсказаний.\n",
    "\n",
    "    Аргументы:\n",
    "        y_true (numpy.ndarray): Истинные значения целевой переменной.\n",
    "        y_pred (numpy.ndarray): Предсказанные значения целевой переменной.\n",
    "    \"\"\"\n",
    "    print(f'R2 score: {r2_score(y_true, y_pred):.4f}')\n",
    "    print(f'RMSE: {mean_squared_error(y_true, y_pred)**0.5:.4f}')\n",
    "    print(f'MAPE: {mean_absolute_percentage_error(y_true, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76776d4a",
   "metadata": {},
   "source": [
    "## **Практическая часть**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1184c9",
   "metadata": {},
   "source": [
    "### **Определения**\n",
    "\n",
    "* **Дерево решений** — это модель, построенная на основе решающих правил вида «если, то», упорядоченных в древовидную иерархическую структуру.\n",
    "\n",
    "* **Узел** (node) — это элемент дерева, который может быть либо внутренним (с условием проверки признака), либо листом (с конечным решением). \n",
    "\n",
    "* **Внутренний узел** — это элемент дерева, который выполняет проверку значений признаков и направляет объекты к подузлам в зависимости от результата проверки.\n",
    "\n",
    "* **Лист** (leaf) — это терминальный узел дерева, принимающий решение, то есть присваивающий объекту конечную метку класса (в задачах классификации) или значение целевой переменной (в задачах регрессии).\n",
    "\n",
    "* **Глубина дерева** — это максимальное число ребер (уровней), которые необходимо пройти, начиная от корневого узла до самого глубокого листового узла."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1290703",
   "metadata": {},
   "source": [
    "### **Деревья решений в задаче классификации**\n",
    "\n",
    "В рамках задачи классификации дерево решений рекурсивно разбивает данные на подмножества, стремясь максимизировать \"чистоту\" узлов, то есть стремясь к ситуации, когда в каждом узле дерева преобладают объекты одного класса.\n",
    "\n",
    "Один из основных способов оценки качества разбиения — **индекс (критерий) Джини (Gini impurity)**, измеряющий вероятность ошибки, если случайно классифицировать объект в узле согласно распределению классов. Чем ниже значение индекса Джини, тем чище множество (лучше разделение).\n",
    "\n",
    "Формула индекса Джини:\n",
    "\n",
    "$$\\text{G}=1-\\sum_{i=1}^{k}{p^{2}_{i}}$$\n",
    "\n",
    "где $k$ — количество классов, $p_{i}$ — доля объектов класса $i$ в узле.\n",
    "\n",
    "Еще одним критерием для оценки разбиения является энтропия:\n",
    "\n",
    "$$\\text{H}=-\\sum_{i=1}^{k}{p_{i}\\log p_{i}}$$\n",
    "\n",
    "Энтропия измеряет степень неопределенности в распределении классов. Энтропия равна нулю, если узел \"чистый\" (все объекты в узле относятся к одному классу), и достигает максимума, если классы распределены равномерно.\n",
    "\n",
    "Оба критерия имеют схожие свойства и часто приводят к похожим результатам, но энтропия сильнее штрафует не однородные узлы. На практике выбор между критериями зависит от конкретной задачи и данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b978a",
   "metadata": {},
   "source": [
    "### ***Задание 1***\n",
    "\n",
    "Сгенерируйте набор данных с двумя классами и двумя признаками с помощью [make_moons](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) (см. код).\n",
    "\n",
    "Реализуйте два простейших дерева решений, дополнив функции one_rule_tree_predict и two_rules_tree_predict:\n",
    "\n",
    "* Дерево с одним узлом (функция one_rule_tree_predict):\n",
    "\n",
    "    * если $x_1 \\le -0.5$, то 0\n",
    "\n",
    "    * иначе: 1\n",
    "\n",
    "* Дерево с двумя узлами (функция two_rules_tree_predict):\n",
    "\n",
    "    * если $x_1 \\le -0.5$, то 0\n",
    "\n",
    "    * иначе:\n",
    "    \n",
    "        * если $x_2 \\le 0$, то 1\n",
    "        \n",
    "        * иначе: 0\n",
    "\n",
    "Дополните класс CustomDecisionTreeClassifier, добавив недостающий код там, где это необходимо.\n",
    "\n",
    "Обучите два дерева решений **c максимальной глубиной 3** на всем наборе данных:\n",
    "\n",
    "* `tree_custom` — дерево CustomDecisionTreeClassifier.\n",
    "\n",
    "* `tree_sk` — дерево DecisionTreeClassifier из библиотеки sklearn.\n",
    "\n",
    "Для каждого из деревьев решений, включая простейшие деревья в виде функций (one_rule_tree_predict, two_rules_tree_predict, `tree_custom`, `tree_sk`), постройте отчёт по метрикам классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2483f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_decision_boundary(classifier, features, labels):\n",
    "    \"\"\"\n",
    "    Визуализирует границу решений классификатора на двумерных данных.\n",
    "\n",
    "    Аргументы:\n",
    "        classifier (callable): Функция или метод модели, принимающий таблицу с признаками и возвращающий предсказанные классы.\n",
    "        features (pandas.DataFrame): Двумерная таблица с признаками (только два признака), по которым строится визуализация.\n",
    "        labels (numpy.ndarray): Массив меток классов.\n",
    "    \"\"\"\n",
    "    x1_min, x1_max = features.iloc[:, 0].min() - 1, features.iloc[:, 0].max() + 1\n",
    "    x2_min, x2_max = features.iloc[:, 1].min() - 1, features.iloc[:, 1].max() + 1\n",
    "    x1x1, x2x2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01), np.arange(x2_min, x2_max, 0.01))\n",
    "    decision = classifier(pd.DataFrame(np.c_[x1x1.ravel(), x2x2.ravel()], columns=features.columns)).reshape(x1x1.shape)\n",
    "    plt.contourf(x1x1, x2x2, decision, alpha=0.5)\n",
    "    plt.scatter(features.iloc[:, 0], features.iloc[:, 1], c=labels, edgecolors='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируйте набор данных с двумя классами и двумя признаками с помощью make_moons\n",
    "\n",
    "features, labels = datasets.make_moons(n_samples=200, noise=0.15, random_state=RANDOM_STATE)\n",
    "features = pd.DataFrame(features)\n",
    "features.columns = ['x1', 'x2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В features два признака: x1 и x2\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55084ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте датасет\n",
    "\n",
    "plt.scatter(features['x1'], features['x2'], c=labels, edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните функцию one_rule_tree_predict\n",
    "\n",
    "def one_rule_tree_predict(features):\n",
    "    \"\"\"\n",
    "    Реализация предсказаний простейшего дерева решений с одним узлом:\n",
    "        если x1 <= -0.5, то 0\n",
    "        иначе: 1\n",
    "\n",
    "    Аргументы:\n",
    "        features (pandas.DataFrame): Таблица с входными признаками.\n",
    "\n",
    "    Возвращает:\n",
    "        numpy.ndarray: Массив предсказанных меток классов.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте отчет по метрикам классификации для one_rule_tree_predict на всем наборе данных\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте границу решений классификатора one_rule_tree_predict на всем наборе данных\n",
    "\n",
    "display_decision_boundary(one_rule_tree_predict, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните функцию two_rules_tree_predict\n",
    "\n",
    "def two_rules_tree_predict(features):\n",
    "    \"\"\"\n",
    "    Реализация предсказаний простейшего дерева решений с двумя узлами:\n",
    "        если x1 <= -0.5, то 0\n",
    "        иначе:\n",
    "            если x2 <= 0, то 1\n",
    "            иначе: 0\n",
    "\n",
    "    Аргументы:\n",
    "        features (pandas.DataFrame): Таблица с входными признаками.\n",
    "\n",
    "    Возвращает:\n",
    "        numpy.ndarray: Массив предсказанных меток классов.   \n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте отчет по метрикам классификации для two_rules_tree_predict на всем наборе данных\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте границу решений классификатора two_rules_tree_predict на всем наборе данных\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d38bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните класс CustomDecisionTreeClassifier\n",
    "# Код методов plot_node, plot_tree и count_nodes изменять не нужно\n",
    "\n",
    "class CustomDecisionTreeClassifier():\n",
    "    \"\"\"\n",
    "    Простой классификатор на основе дерева решений с критерием Джини в качестве критерия разделения.\n",
    "\n",
    "    Аргументы:\n",
    "        max_depth (int): Максимальная глубина дерева. По умолчанию — 3.\n",
    "\n",
    "    Атрибуты:\n",
    "        label (int): Метка класса, который наиболее часто встречается в узле.\n",
    "        feature (str): Признак, используемый для разделения.\n",
    "        size (int): Количество объектов в узле.\n",
    "        threshold (float): Пороговое значение для разделения.\n",
    "        left (CustomDecisionTreeClassifier): Левое поддерево (значение <= порог).\n",
    "        right (CustomDecisionTreeClassifier): Правое поддерево (значение > порог).\n",
    "        gini (float): Индекс Джини в узле.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth\n",
    "        self.label = None\n",
    "        self.feature = None\n",
    "        self.size = None\n",
    "        self.threshold = np.nan\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.gini = 0\n",
    "\n",
    "    def gini_impurity(self, y):\n",
    "        \"\"\"\n",
    "        Вычисляет индекс Джини для массива меток классов.\n",
    "\n",
    "        Аргументы:\n",
    "            y (numpy.ndarray): Массив меток классов.\n",
    "\n",
    "        Возвращает:\n",
    "            float: Значение индекса Джини.\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        return ...\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Находит оптимальный признак и порог для разделения данных.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив меток классов.\n",
    "\n",
    "        Возвращает:\n",
    "            tuple:\n",
    "                str: Оптимальный признак для разделения.\n",
    "                float: Оптимальное пороговое значение.\n",
    "                float: Значение индекса Джини после оптимального разделения.\n",
    "        \"\"\"\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gini = self.gini_impurity(y)\n",
    "        N = X.shape[0]\n",
    "        for feature in X.columns:\n",
    "            values = np.sort(X[feature].unique())\n",
    "            thresholds = [(values[i] + values[i+1]) / 2 for i in range(len(values)-1)]\n",
    "            for threshold in thresholds:\n",
    "                mask_left = X[feature] <= threshold\n",
    "                mask_right = ~mask_left\n",
    "                N_left = ...\n",
    "                N_right = ...\n",
    "                if N_left == 0 or N_right == 0:\n",
    "                    continue  \n",
    "                gini_left = ...\n",
    "                gini_right = ...\n",
    "                weighted_gini = (N_left * gini_left + N_right * gini_right) / N\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, best_gini\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает дерево решений, рекурсивно находя оптимальные разделения.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив меток классов.\n",
    "\n",
    "        Возвращает:\n",
    "            CustomDecisionTreeClassifier: Обученное дерево решений.\n",
    "        \"\"\"\n",
    "        self.size = len(y)\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        self.label = classes[np.argmax(counts)]\n",
    "        self.gini = self.gini_impurity(y)\n",
    "        if self.max_depth == 0:\n",
    "            return \n",
    "        self.feature, self.threshold, gini = self.best_split(X, y)\n",
    "        if self.feature is None or gini >= self.gini:\n",
    "            return\n",
    "        self.gini = gini\n",
    "        mask_left = ...\n",
    "        mask_right = ...\n",
    "        self.left = CustomDecisionTreeClassifier(...)\n",
    "        self.right = CustomDecisionTreeClassifier(...)\n",
    "        self.left.fit(...)\n",
    "        self.right.fit(...)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает метки классов.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "\n",
    "        Возвращает:\n",
    "            numpy.ndarray: Массив предсказанных меток классов.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return np.full(X.shape[0], self.label)  \n",
    "        mask_left = ...\n",
    "        mask_right = ...\n",
    "        y_pred = np.empty(X.shape[0])\n",
    "        y_pred[mask_left] = self.left.predict(X[mask_left])\n",
    "        y_pred[mask_right] = self.right.predict(X[mask_right])\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def plot_node(self, dot, node_id=0):\n",
    "        \"\"\"\n",
    "        Вспомогательный метод для визуализации дерева.\n",
    "\n",
    "        Аргументы:\n",
    "            dot (graphviz.Digraph): Объект Digraph библиотеки graphviz.\n",
    "            node_id (int): Идентификатор текущего узла. По умолчанию — 0.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Идентификатор узла.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            label = f\"gini = {self.gini:.3f}\\nsamples = {self.size}\\nlabel = {self.label}\"\n",
    "            dot.node(str(node_id), label=label, fillcolor=\"#8ccd96\")\n",
    "            return node_id\n",
    "        label = f\"{self.feature} <= {self.threshold:.3f}\\ngini = {self.gini:.3f}\\nsamples = {self.size}\\nlabel = {self.label}\"\n",
    "        dot.node(str(node_id), label=label, fillcolor=\"#ffffff\")\n",
    "        left_id = self.left.plot_node(dot, node_id*2 + 1)\n",
    "        dot.edge(str(node_id), str(left_id))\n",
    "        right_id = self.right.plot_node(dot, node_id*2 + 2)\n",
    "        dot.edge(str(node_id), str(right_id))\n",
    "        \n",
    "        return node_id\n",
    "\n",
    "    def plot_tree(self, filled=True):\n",
    "        \"\"\"\n",
    "        Генерирует визуализацию дерева решений.\n",
    "\n",
    "        Аргументы:\n",
    "            filled (bool): Закрашивать узлы. По умолчанию — True.\n",
    "\n",
    "        Возвращает:\n",
    "            graphviz.Digraph: Объект graphviz с визуализацией дерева.\n",
    "        \"\"\"\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.attr('node', shape='box', style='filled' if filled else None)\n",
    "        self.plot_node(dot)\n",
    "        return dot\n",
    "    \n",
    "    def count_nodes(self):\n",
    "        \"\"\"\n",
    "        Рассчитывает сложность дерева — совокупное количество узлов в дереве.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Общее количество узлов.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return 1\n",
    "        return 1 + self.left.count_nodes() + self.right.count_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cad688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите дерево tree_custom (CustomDecisionTreeClassifier)\n",
    "# Максимальная глубина — 3\n",
    "\n",
    "tree_custom = CustomDecisionTreeClassifier(...)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте отчет по метрикам классификации для tree_custom на всем наборе данных\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b874c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте границу решений классификатора tree_custom на всем наборе данных\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте дерево tree_custom\n",
    "\n",
    "tree_custom.plot_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d459ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите дерево tree_sk (DecisionTreeClassifier)\n",
    "# Максимальная глубина — 3\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "tree_sk = DecisionTreeClassifier(...)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc39f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте отчет по метрикам классификации для tree_sk на всем наборе данных\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте границу решений классификатора tree_sk на всем наборе данных\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте дерево tree_sk\n",
    "\n",
    "_ = plot_tree(tree_sk, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37278a",
   "metadata": {},
   "source": [
    "### **Деревья решений: масштабирование признаков и обработка пропущенных значений**\n",
    "\n",
    "Особенностью деревьев решений и основанных на них ансамблевых методов (случайный лес, градиентный бустинг) является их устойчивость к некоторым распространённым проблемам предобработки данных, которые являются критичными для многих других алгоритмов машинного обучения.\n",
    "\n",
    "В частности, деревьям решений и ансамблевым методам, основанным на деревьях, не требуется масштабирование признаков, поскольку масштабирование не влияет на структуру дерева и на то, какие признаки будут выбраны для разделения и в каком порядке. Это связано с тем, что деревья решений строят свои правила разделения данных (сплиты) на основе пороговых значений для каждого признака, вне зависимости от его исходного масштаба.\n",
    "\n",
    "Кроме того, деревья решений и их ансамбли, как правило, могут эффективно использовать данные с пропущенными значениями без явной предварительной их обработки. Это связано с их способностью адаптироваться к таким данным: различные реализации алгоритмов деревьев имеют встроенные механизмы для работы с пропущенными значениями:\n",
    "\n",
    "* Создание отдельной ветви для пропущенных значений (XGBoost и LightGBM). Если признак используется для разделения, и для некоторых наблюдений его значение отсутствует, эти наблюдения направляются в отдельную ветвь.\n",
    "\n",
    "* Направление в ветку с большинством наблюдений (DecisionTreeClassifier и DecisionTreeRegressor). Пропуски направляются в ту ветвь, которая содержит большинство наблюдений (или обеспечивает наилучшее качество сплита) из обучающего набора, для которых значение признака известно.\n",
    "\n",
    "Тем не менее, методы обработки пропущенных значений для деревьев решений и ансамблевых методов могут быть полезны для некоторых сценариев. Например, для сравнения с другими моделями или для более глубокого анализа данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d15b07",
   "metadata": {},
   "source": [
    "### **Методы борьбы с переобучением деревьев**\n",
    "\n",
    "Существенный недостаток деревьев решений — **склонность к переобучению**, в частности при отсутствии ограничений на рост. \n",
    "\n",
    "Переобучение дерева решений проявляется в чрезмерном ветвлении, чувствительности к данным и высокой дисперсии предсказаний: сложное дерево дает очень точные предсказания на обучающей выборке, но ошибается на тестовой.\n",
    "\n",
    "**Основные методы борьбы с переобучением:**\n",
    "\n",
    "* Подбор параметров дерева:\n",
    "\n",
    "    * max_depth — максимальная глубина дерева.\n",
    "\n",
    "    * min_samples_split — минимальное количество объектов для разбиения узла.\n",
    "\n",
    "    * min_samples_leaf — минимальное количество объектов в листе.\n",
    "\n",
    "* Прунинг (обрезка) дерева — удаление избыточных ветвей после построения дерева на основе их значимости **без учёта сложности дерева**.\n",
    "\n",
    "* Cost-Complexity Pruning — это метод, суть которого состоит в нахождении **компромисса (баланса) между точностью модели и сложностью дерева**.\n",
    "    \n",
    "* Ансамблевые методы (будут рассмотрены в следующих темах курса):\n",
    "\n",
    "    * Случайный лес (random forest) — усреднение предсказаний множества деревьев с разными подвыборками данных и признаков.\n",
    "\n",
    "    * Градиентный бустинг (gradient boosting) — последовательное улучшение модели за счет добавления деревьев, исправляющих ошибки предыдущих."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9ceba",
   "metadata": {},
   "source": [
    "### **Деревья решений в задаче регрессии**\n",
    "\n",
    "Деревья решений могут также применяться для задачи регрессии. В отличие от классификации, где листья дерева содержат метки классов, в регрессии каждый лист возвращает числовое значение — среднее (или медиану) целевой переменной для объектов, попавших в этот лист.\n",
    "\n",
    "При построении дерева разбиение выбирается так, чтобы максимально уменьшить функцию ошибки (MSE, MAE и др.) в дочерних узлах по сравнению с родительским."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c7225",
   "metadata": {},
   "source": [
    "### **Датасет *California Housing dataset***\n",
    "\n",
    "**Для решения заданий 2 — 3 рассмотрим датасет [California Housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset).**\n",
    "\n",
    "Набор данных предназначен для прогнозирования медианной стоимости домов по районам штата Калифорния на основе агрегированных показателей. Датасет содержит 20640 наблюдений без пропущенных значений и сформирован на основе переписи населения США 1990 года с разбивкой по районам городов.\n",
    "\n",
    "Целевая переменная — target (медианная стоимость домов в районе, выраженная в сотнях тысяч долларов).\n",
    "\n",
    "Признаки:\n",
    "\n",
    "* MedInc — медианный доход в районе.\n",
    "\n",
    "* HouseAge — медианный возраст домов в районе.\n",
    "\n",
    "* AveRooms — среднее количество комнат в домах района.\n",
    "\n",
    "* AveBedrms — среднее количество спален в домах района.\n",
    "\n",
    "* Population — численность населения в районе.\n",
    "\n",
    "* AveOccup — среднее число членов домохозяйства в районе.\n",
    "\n",
    "* Latitude — географическая широта района.\n",
    "\n",
    "* Longitude — географическая долгота района."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565eac29",
   "metadata": {},
   "source": [
    "### ***Задание 2***\n",
    "\n",
    "Дополните класс CustomDecisionTreeRegressor (функция ошибки — MSE), добавив недостающий код, где это необходимо. В рамках класса CustomDecisionTreeRegressor необходимо также реализовать метод prune для рекурсивного прунинга (обрезки) дерева по следующему алгоритму:\n",
    "\n",
    "* Рекурсивный обход дерева начинается с листьев и движется к корню дерева по узлам. Для каждого узла дерева:\n",
    "\n",
    "    1. Вычисляется взвешенная ошибка дочерних узлов:\n",
    "\n",
    "    $$\\text{MSE}_{\\text{weighted}}=\\frac{N_{\\text{left}}\\times \\text{MSE}_{\\text{left}}+N_{\\text{right}}\\times \\text{MSE}_{\\text{right}}}{N_{\\text{left}}+N_{\\text{right}}}$$\n",
    "\n",
    "    где $N_{\\text{left}}$ и $N_{\\text{right}}$ — количество объектов в дочерних узлах.\n",
    "\n",
    "    2. Проверяется критерий обрезки — малое (меньше $\\varepsilon$) улучшение ошибки родительского узла:\n",
    "\n",
    "    $$\\text{MSE}_{\\text{parent}}-\\text{MSE}_{\\text{weighted}} < \\varepsilon$$\n",
    "\n",
    "    3. Если критерий выполняется (**улучшение $\\text{MSE}$ меньше $\\varepsilon$**), то поддерево можно удалить, заменив его листом.\n",
    "\n",
    "Обучите дерево решений `tree_housing_custom` (CustomDecisionTreeRegressor) на обучающей выборке с максимальной глубиной 8.\n",
    "\n",
    "Обучите аналогичное дерево решений `tree_housing_custom_pruned` (CustomDecisionTreeRegressor) на обучающей выборке с максимальной глубиной 8 и выполните его обрезку (прунинг) с помощью метода prune. В качестве порогового значения для обрезки используйте epsilon=0.02.\n",
    "\n",
    "Выведите metrics_report для моделей `tree_housing_custom` и `tree_housing_custom_pruned` **на обучающей и тестовой выборке** и сравните сложности (совокупное количество улов в дереве) деревьев (метод count_nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bffeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузите набор данных с помощью sklearn.datasets и выделите объясняемый фактор в отдельную переменную\n",
    "\n",
    "df_housing = datasets.fetch_california_housing()\n",
    "X_housing = pd.DataFrame(df_housing.data)\n",
    "X_housing.columns = df_housing.feature_names\n",
    "X_housing = X_housing.sample(2000, random_state=RANDOM_STATE)   # Случайным образом выберем 2000 наблюдений\n",
    "y_housing = df_housing.target[X_housing.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10dfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделите датасет на обучающую (60%) и тестовую (40%) выборки\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "X_housing_train, X_housing_test, y_housing_train, y_housing_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bc19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните класс CustomDecisionTreeRegressor\n",
    "# Код методов plot_node, plot_tree и count_nodes изменять не нужно\n",
    "\n",
    "class CustomDecisionTreeRegressor():\n",
    "    \"\"\"\n",
    "    Простой регрессор на основе дерева решений с ошибкой MSE в качестве критерия разделения и средним значением в листе для прогноза.\n",
    "\n",
    "    Аргументы:\n",
    "        max_depth (int): Максимальная глубина дерева. По умолчанию — 8.\n",
    "\n",
    "    Атрибуты:\n",
    "        value (float): Среднее значение целевой переменной в узле.\n",
    "        feature (str): Признак, используемый для разделения.\n",
    "        size (int): Количество объектов в узле.\n",
    "        threshold (float): Пороговое значение для разделения.\n",
    "        left (CustomDecisionTreeRegressor): Левое поддерево (значение <= порог).\n",
    "        right (CustomDecisionTreeRegressor): Правое поддерево (значение > порог).\n",
    "        mse (float): Ошибка MSE в узле.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=8):\n",
    "        self.max_depth = max_depth\n",
    "        self.value = None\n",
    "        self.feature = None\n",
    "        self.size = None\n",
    "        self.threshold = np.nan\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.mse = 0\n",
    "\n",
    "\n",
    "    def MSE(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Вычисляет среднеквадратичную ошибку (MSE).\n",
    "\n",
    "        Аргументы:\n",
    "            y_true (numpy.ndarray): Массив истинных значений целевой переменной.\n",
    "            y_pred (numpy.ndarray): Массив предсказанных значений целевой переменной.\n",
    "\n",
    "        Возвращает:\n",
    "            float: Значение MSE.\n",
    "        \"\"\"\n",
    "        return ...\n",
    "\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Находит оптимальный признак и порог для разделения данных.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив значений целевой переменной.\n",
    "\n",
    "        Возвращает:\n",
    "            tuple:\n",
    "                str: Оптимальный признак для разделения.\n",
    "                float: Оптимальное пороговое значение.\n",
    "                float: Значение среднеквадратичной ошибки (MSE) после разделения.\n",
    "        \"\"\"\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_mse = self.MSE(y, y.mean())\n",
    "        N = X.shape[0]\n",
    "        for feature in X.columns:\n",
    "            values = np.sort(X[feature].unique())\n",
    "            thresholds = [(values[i] + values[i+1]) / 2 for i in range(len(values) - 1)]\n",
    "            for threshold in thresholds:\n",
    "                mask_left = ...\n",
    "                mask_right = ...\n",
    "                N_left = ...\n",
    "                N_right = ...\n",
    "                if N_left == 0 or N_right == 0:\n",
    "                    continue\n",
    "                loss_left = ...\n",
    "                loss_right = ...\n",
    "                weighted_mse = ...\n",
    "                if weighted_mse < best_mse:\n",
    "                    best_mse = weighted_mse\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold, best_mse\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучает дерево решений, рекурсивно находя оптимальные разделения.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "            y (numpy.ndarray): Массив значений целевой переменной.\n",
    "\n",
    "        Возвращает:\n",
    "            CustomDecisionTreeRegressor: Обученное дерево решений.\n",
    "        \"\"\"\n",
    "        self.value = y.mean()\n",
    "        self.mse = self.MSE(y, self.value)\n",
    "        self.size = len(y)\n",
    "        if self.max_depth == 0:\n",
    "            return\n",
    "        self.feature, self.threshold, mse = self.best_split(X, y)\n",
    "        if self.feature is None or mse >= self.mse:\n",
    "            return\n",
    "        self.mse = mse\n",
    "        mask_left = ...\n",
    "        mask_right = ...\n",
    "        self.left = CustomDecisionTreeRegressor(...)\n",
    "        self.right = CustomDecisionTreeRegressor(...)\n",
    "        self.left.fit(...)\n",
    "        self.right.fit(...)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказывает значения целевой переменной.\n",
    "\n",
    "        Аргументы:\n",
    "            X (pandas.DataFrame): Таблица с признаками.\n",
    "\n",
    "        Возвращает:\n",
    "            numpy.ndarray: Массив предсказанных значений целевой переменной.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return np.full(X.shape[0], self.value)\n",
    "        mask_left = ...\n",
    "        mask_right = ...\n",
    "        y_pred = np.empty(X.shape[0])\n",
    "        y_pred[mask_left] = self.left.predict(...)\n",
    "        y_pred[mask_right] = self.right.predict(...)\n",
    "        return y_pred\n",
    "    \n",
    "    def prune(self, epsilon):\n",
    "        \"\"\"\n",
    "        Обрезает дерево, если разница ошибок между родительским и дочерними узлами меньше epsilon.\n",
    "        После обрезки внутренний узел становится листом.\n",
    "\n",
    "        Аргументы:\n",
    "            epsilon (float): Пороговое значение для обрезки.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return\n",
    "        self.left.prune(...)\n",
    "        self.right.prune(...)\n",
    "        left_size = ...\n",
    "        right_size = ...\n",
    "        left_mse = ...\n",
    "        right_mse = ...\n",
    "        weighted_mse = ...\n",
    "        if weighted_mse > 0 and ...:\n",
    "            self.feature = None\n",
    "            self.threshold = np.nan\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "    \n",
    "    def plot_node(self, dot, node_id=0):\n",
    "        \"\"\"\n",
    "        Вспомогательный метод для визуализации дерева.\n",
    "\n",
    "        Аргументы:\n",
    "            dot (graphviz.Digraph): Объект Digraph библиотеки graphviz.\n",
    "            node_id (int): Идентификатор текущего узла. По умолчанию — 0.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Идентификатор узла.\n",
    "        \"\"\"\n",
    "        if self.feature == None:\n",
    "            dot.node(str(node_id), label='mse = {:.3f}\\nsamples = {}\\nvalue = {:.3f}'.format(self.mse, self.size, self.value), fillcolor=\"#8ccd96\")\n",
    "            return node_id\n",
    "        dot.node(str(node_id), label='{} <= {:.3f}\\nmse = {:.3f}\\nsamples = {}\\nvalue = {:.3f}'\n",
    "                 .format(self.feature, self.threshold, self.mse, self.size, self.value), fillcolor=\"#ffffff\")\n",
    "        left_id = self.left.plot_node(dot, node_id*2 + 1)\n",
    "        dot.edge(str(node_id), str(left_id))\n",
    "        right_id = self.right.plot_node(dot, node_id*2 + 2)\n",
    "        dot.edge(str(node_id), str(right_id))\n",
    "        return node_id\n",
    "    \n",
    "    def plot_tree(self, filled=True):\n",
    "        \"\"\"\n",
    "        Генерирует визуализацию дерева решений.\n",
    "\n",
    "        Аргументы:\n",
    "            filled (bool): Закрашивать узлы. По умолчанию — True.\n",
    "\n",
    "        Возвращает:\n",
    "            graphviz.Digraph: Объект graphviz с визуализацией дерева.\n",
    "        \"\"\"\n",
    "        dot = graphviz.Digraph()\n",
    "        dot.attr('node', shape='box', style='filled' if filled else None)\n",
    "        self.plot_node(dot)\n",
    "        return dot\n",
    "    \n",
    "    def count_nodes(self):\n",
    "        \"\"\"\n",
    "        Рассчитывает сложность дерева — совокупное количество узлов в дереве.\n",
    "\n",
    "        Возвращает:\n",
    "            int: Общее количество узлов.\n",
    "        \"\"\"\n",
    "        if self.feature is None:\n",
    "            return 1\n",
    "        return 1 + self.left.count_nodes() + self.right.count_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите дерево tree_housing_custom (CustomDecisionTreeRegressor)\n",
    "# Максимальная глубина — 8\n",
    "\n",
    "tree_housing_custom = CustomDecisionTreeRegressor(...)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите metrics_report для дерева tree_housing_custom на обучающей и тестовой выборках\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите сложность дерева tree_housing_custom\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте дерево tree_housing_custom (не обязательно)\n",
    "\n",
    "tree_housing_custom.plot_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите дерево tree_housing_custom_pruned (CustomDecisionTreeRegressor) и выполните его обрезку с помощью метода prune\n",
    "# Максимальная глубина — 8 \n",
    "# epsilon=0.02\n",
    "\n",
    "tree_housing_custom_pruned = CustomDecisionTreeRegressor(...)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34112e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите metrics_report для дерева tree_housing_custom_pruned на обучающей и тестовой выборках\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите сложность дерева tree_housing_custom_pruned\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте дерево tree_housing_custom_pruned (не обязательно)\n",
    "\n",
    "tree_housing_custom_pruned.plot_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25187724",
   "metadata": {},
   "source": [
    "### **Cost-Complexity Pruning**\n",
    "\n",
    "**Cost-Complexity Pruning** (CCP) — это метод борьбы с переобучением в деревьях решений, суть которого состоит в нахождении оптимального баланса между точностью модели и сложностью дерева.\n",
    "\n",
    "Общий критерий оптимизации:\n",
    "\n",
    "$$R_{\\alpha}(T)=R(T)+\\alpha|T|$$\n",
    "\n",
    "где $R(T)$ — ошибка дерева (к примеру, MSE/MAE для регрессии или Gini/Entropy для классификации), $|T|$ — количество листьев в дереве, $\\alpha$ — параметр регуляризации.\n",
    "\n",
    "Cost-Complexity Pruning в sklearn для деревьев решений (DecisionTreeClassifier и DecisionTreeRegressor) реализуется с помощью **параметра ccp_alpha**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e62102",
   "metadata": {},
   "source": [
    "### ***Задание 3***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обучающую и тестовую выборку из задания 2: `X_housing_train`, `X_housing_test`, `y_housing_train`, `y_housing_test`.\n",
    "\n",
    "Обучите дерево решений `tree_housing` (DecisionTreeRegressor) без ограничений на глубину дерева.\n",
    "\n",
    "С помощью модели `tree_housing` рассчитайте все возможные значения параметра ccp_alpha (`ccp_alphas`), используя метод [cost_complexity_pruning_path](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#post-pruning-decision-trees-with-cost-complexity-pruning).\n",
    "\n",
    "Подберите оптимальное значение параметра ccp_alpha, перебрав все возможные значения `ccp_alphas` с помощью GridSearchCV.\n",
    "\n",
    "Обучите дерево решений `tree_housing_ccp` (DecisionTreeRegressor) с оптимальным параметром ccp_alpha.\n",
    "\n",
    "Выведите metrics_report для моделей `tree_housing` и `tree_housing_ccp` **на обучающей и тестовой выборке** и сравните сложности деревьев (метод count_nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38031b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите дерево tree_housing без ограничений\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "tree_housing = DecisionTreeRegressor(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b353ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите metrics_report для дерева tree_housing на обучающей и тестовой выборках\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте сложность дерева tree_housing\n",
    "\n",
    "tree_housing.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a553ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# С помощью tree_housing рассчитайте все возможные значения ccp_alpha, используя метод cost_complexity_pruning_path\n",
    "\n",
    "ccp_alphas = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подберите оптимальное значение ccp_alpha с помощью GridSearchCV\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "params = {'ccp_alpha': ccp_alphas}\n",
    "scoring='neg_mean_squared_error'\n",
    "cv = 5\n",
    "\n",
    "cv_tree_housing_ccp = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график MSE ~ ccp_alpha по результатам кросс-валидации\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ccp_alphas, -cv_tree_housing_ccp.cv_results_['mean_test_score'], marker='.', drawstyle='steps-post')\n",
    "plt.scatter(cv_tree_housing_ccp.best_params_['ccp_alpha'], -cv_tree_housing_ccp.best_score_, c='red', label='Оптимальный ccp_alpha')\n",
    "plt.xlabel('ccp_alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb76ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите дерево tree_housing_ccp с оптимальным параметром ccp_alpha\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "tree_housing_ccp = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите metrics_report для дерева tree_housing_ccp на обучающей и тестовой выборках\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44455149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте сложность дерева tree_housing_ccp\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте дерево tree_housing_ccp\n",
    "\n",
    "dot_data = tree.export_graphviz(tree_housing_ccp, out_file=None,\n",
    "                                feature_names=X_housing_train.columns,\n",
    "                                filled=True)\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1389a3",
   "metadata": {},
   "source": [
    "## **Предсказание временных рядов с помощью деревьев решений**\n",
    "\n",
    "Деревья решений (и ансамбли на их основе) не могут быть использованы для прогнозирования временных рядом, содержащих тренд (долгосрочное возрастание или убывание значений), поскольку:\n",
    "\n",
    "1. Дерево решений разбивает данные на основе признаков (например, год, месяц), но не учитывает их изменение со временем.\n",
    "\n",
    "2. Если тренд сильный, дерево решений будет аппроксимировать его кусочно-линейными приближениями, что даст плохие прогнозы на новых данных.\n",
    "\n",
    "3. Деревья не экстраполируют за пределы обучающей выборки: деревья не могут предсказать значения выше или ниже тех, что были использованы при обучении.\n",
    "\n",
    "Одним из решений этой проблемы является переход от значений временного ряда с трендом к абсолютным приростам (разностям первого порядка):\n",
    "\n",
    "$$\\Delta y_{t}=y_{t}-y_{t-1}$$\n",
    "\n",
    "где $y_{t}$ — истинное значение временного ряда в момент времени $t$.\n",
    "\n",
    "После предсказания приростов $\\Delta \\hat{y_{t}}$​ можно восстановить исходный ряд:\n",
    "\n",
    "$$\\hat{y_{t}}=y_{0}+\\sum_{i=1}^{t}{\\Delta \\hat{y_{t}}}$$\n",
    "\n",
    "где $y_{0}$​ — начальное значение ряда.\n",
    "\n",
    "Если прогноз выполняется рекурсивно (уже предсказанные значения используются для построения прогноза на следующие шаги), то возникает проблема накопления ошибок — ошибки суммируются на каждом шаге рекурсивного прогноза временного ряда. Это приведёт к тому, что итоговый прогноз $\\hat{y_{t}}$ может значительно отклоняться от реальных значений временного ряда."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca351b6",
   "metadata": {},
   "source": [
    "### **Датасет *Retail Sales: Restaurants and Other Eating Places***\n",
    "\n",
    "**Для решения задания 4 рассмотрим датасет [Retail Sales: Restaurants and Other Eating Places](https://fred.stlouisfed.org/series/MRTSSM7225USN).**\n",
    "\n",
    "**ВНИМАНИЕ:** При решении задания **используйте файл retail_sales.csv** из приложения к ноутбуку, поскольку исходный датасет был изменен авторами курса.\n",
    "\n",
    "Набор данных представляет собой временной ряд с ежемесячной частотой данных. Он предназначен для анализа тенденций и изменений в объёмах продаж в ресторанном бизнесе и сфере общественного питания в США.\n",
    "\n",
    "Целевая переменная — RetailSales (совокупный ежемесячный объём продаж, млн. долларов США).\n",
    "\n",
    "Рассмотрим период с января 1992 года по июнь 2019 года."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7a2de",
   "metadata": {},
   "source": [
    "### ***Задание 4***\n",
    "\n",
    "Используя значения ряда (RetailSales), создайте признаки:\n",
    "\n",
    "* Лаговые признаки (*подсказка: используйте [shift](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html)*):\n",
    "\n",
    "    * lag 1m — значение RetailSales 1 месяц назад (временной лаг в 1 наблюдение).\n",
    "\n",
    "    * lag 12m — значение RetailSales 12 месяцев назад (временной лаг в 12 наблюдений).\n",
    "\n",
    "* Скользящее среднее (*подсказка: используйте признак **lag 1m** (скользящее среднее строится по **предыдущим** наблюдениям и не должно включать значение целевой переменной на момент прогноза) и [rolling](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html)*):\n",
    "\n",
    "    * mean 3m — среднее RetailSales за **предыдущие** 3 месяца (скользящее среднее по 3 **предыдущим** наблюдениям).\n",
    "\n",
    "    * mean 12m — среднее RetailSales за **предыдущие** 12 месяцев (скользящее среднее по 12 **предыдущим** наблюдениям).\n",
    "\n",
    "Используя метку времени (Date), создайте признаки:\n",
    "\n",
    "* Временные компоненты:\n",
    "\n",
    "    * day: число месяца.\n",
    "\n",
    "    * month: месяц.\n",
    "\n",
    "    * year: год.\n",
    "\n",
    "* Циклические признаки, закодированные с помощью косинуса и синуса ($x_{\\text{cos}} = \\text{cos}(\\frac{2 \\pi x}{T})$, $x_{\\text{sin}} = \\text{sin}(\\frac{2 \\pi x}{T})$):\n",
    "\n",
    "    * day_cos, day_sin: cos и sin от day ($T = 30$).\n",
    "\n",
    "    * month_cos, month_sin: cos и sin от month ($T = 12$).\n",
    "\n",
    "Разделите датасет на обучающую и тестовую выборки так, чтобы в обучающую выборку вошли все данные ранее 2016 года, в тестовую — все данные за 2016 год и позже.\n",
    "\n",
    "Обучите дерево решений `tree_retail` (DecisionTreeRegressor) с ограничениями:\n",
    "\n",
    "* min_samples_split=5.\n",
    "\n",
    "* min_samples_leaf=2.\n",
    "\n",
    "Используя данные после создания временных переменных и до разделения на обучающую и тестовую выборки (`X_retail`, `y_retail`), выделите новую объясняемую переменную `y_retail_diff` — абсолютные приросты значений временного ряда (**выполните переход от значений ряда к абсолютным приростам**), и **заново разделите датасет на обучающую и тестовую выборки** так, чтобы в обучающую выборку вошли все данные ранее 2016 года, в тестовую — все данные за 2016 год и позже.\n",
    "\n",
    "Обучите дерево решений `tree_retail_diff` (DecisionTreeRegressor) с теми же ограничениями, что и у дерева `tree_retail`, в качестве **объясняемой переменной используя абсолютные приросты**.\n",
    "\n",
    "Выведите metrics_report для моделей `tree_retail` и `tree_retail_diff` **на обучающей и тестовой выборке**.\n",
    "\n",
    "**На тестовой выборке** преобразуйте предсказанные  моделью `tree_retail_diff` абсолютные приросты в исходные значения временного ряда и выведите metrics_report после обратного перехода к исходным значениям.\n",
    "\n",
    "**ВНИМАНИЕ:** Обратите внимание, что в данном задании рассматривается упрощённый пример прогнозирования временного ряда на один временной период вперёд (на один месяц вперед). Для прогноза всегда используются истинные значения временных признаков, в том числе в рамках тестовой выборки. Таким образом, в данном примере модель не подвержена накоплению ошибки, поскольку такой прогноз не является рекурсивным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считайте набор данных\n",
    "\n",
    "df_retail = pd.read_csv('retail.csv')\n",
    "df_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признак Date имеет тип данных object\n",
    "# Необходимо изменить тип данных для Date\n",
    "\n",
    "df_retail.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Измените тип Date на datetime64[ns]\n",
    "\n",
    "df_retail['Date'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убедитесь, что тип данных Date — datetime64[ns]\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график значений временного ряда (RetailSales)\n",
    "\n",
    "df_retail.plot(x='Date', y='RetailSales', figsize=(12, 10))\n",
    "plt.xlabel('Время')\n",
    "plt.ylabel('Объём продаж, млн. долл. США')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16814c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте признаки lag 1m и lag 12m\n",
    "# Подсказка: используйте shift\n",
    "\n",
    "df_retail['lag 1m'] = ...\n",
    "df_retail['lag 12m'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a54981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте признаки mean 3m и mean 12m\n",
    "# Подсказка: используйте признак lag 1m и rolling\n",
    "\n",
    "df_retail['mean 3m'] = ...\n",
    "df_retail['mean 12m'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94185bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируйте метку времени (Date) как временные компоненты \n",
    "\n",
    "df_retail['day'] = ...\n",
    "df_retail['month'] = ...\n",
    "df_retail['year'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируйте циклические переменные с помощью косинуса и синуса\n",
    "\n",
    "df_retail['day_cos'] = ...\n",
    "df_retail['day_sin'] = ...\n",
    "\n",
    "df_retail['month_cos'] = ...\n",
    "df_retail['month_sin'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Датасет после создания признаков\n",
    "\n",
    "df_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалите строки с пропущенными значениями\n",
    "# Пропущенные значения появились после создания лаговых признаков и скользящих средних\n",
    "\n",
    "df_retail = df_retail.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0153870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установите метку времени (Date) как индекс датасета df_retail\n",
    "\n",
    "df_retail = df_retail.set_index('Date', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделите объясняемый фактор в отдельную переменную\n",
    "\n",
    "X_retail, y_retail = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbfd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделите датасет на обучающую и тестовую выборки:\n",
    "#   Обучающая выборка — все данные ранее 2016 года\n",
    "#   Тестовая выборка  — все данные за 2016 год и позже\n",
    "\n",
    "X_retail_train = ...\n",
    "y_retail_train = ...\n",
    "\n",
    "X_retail_test = ...\n",
    "y_retail_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# На обучающей выборке обучите дерево решений tree_retail (DecisionTreeRegressor) с ограничениями:\n",
    "#   min_samples_split=5\n",
    "#   min_samples_leaf=2\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "tree_retail = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2deb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите metrics_report для дерева tree_retail на обучающей и тестовой выборках\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94554c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график значений временного ряда (RetailSales)\n",
    "# Добавьте на график прогноз значений ряда моделью tree_retail\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(X_retail.index, y_retail, alpha=0.8, label='Истинные значения ряда')\n",
    "plt.plot(X_retail.index, ..., c='red', label='Прогноз ряда с помощью tree_retail')\n",
    "plt.xlabel('Время')\n",
    "plt.ylabel('Объём продаж, млн. долл. США')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделите новую объясняемую переменную y_retail_diff — абсолютные приросты значений временного ряда\n",
    "# Подсказка: используйте shift\n",
    "\n",
    "y_retail_diff = ...\n",
    "y_retail_diff = y_retail_diff[1:]\n",
    "X_retail_diff = X_retail[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделите датасет на обучающую и тестовую выборки:\n",
    "#   Обучающая выборка — все данные ранее 2016 года\n",
    "#   Тестовая выборка  — все данные за 2016 год и позже\n",
    "\n",
    "X_retail_diff_train = ...\n",
    "y_retail_diff_train = ...\n",
    "\n",
    "X_retail_diff_test = ...\n",
    "y_retail_diff_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# На обучающей выборке обучите дерево tree_retail_diff (DecisionTreeRegressor) с ограничениями:\n",
    "#   min_samples_split=5\n",
    "#   min_samples_leaf=2\n",
    "# В качестве объясняемой переменной используйте абсолютные приросты\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "tree_retail_diff = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите metrics_report для дерева tree_retail_diff на обучающей и тестовой выборках (в абсолютных приростах)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график значений абсолютных приростов\n",
    "# Добавьте на график прогноз абсолютных приростов моделью tree_retail_diff\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(X_retail_diff.index, y_retail_diff, alpha=0.8, label='Истинные значения абсолютных приростов')\n",
    "plt.plot(X_retail_diff.index, ..., c='green', label='Прогноз абсолютных приростов с помощью tree_retail_diff')\n",
    "plt.xlabel('Время')\n",
    "plt.ylabel('Объём продаж, млн. долл. США')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072aff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# На тестовой выборке преобразуйте предсказанные моделью tree_retail_diff абсолютные приросты в исходные значения временного ряда \n",
    "\n",
    "y_test_pred_tree_retail_diff = y_retail_train[-1] + ... # В качестве y0 используем последнее истинное значение в train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите metrics_report на тестовой выборке после обратного перехода от прогноза приростов к исходным значениям\n",
    "\n",
    "metrics_report(y_retail_test, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график значений временного ряда (RetailSales) на тестовой выборке\n",
    "# Добавьте на график прогноз значений ряда с помощью моделей tree_retail и tree_retail_diff\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(X_retail_test.index, y_retail_test, marker='.', alpha=0.8, label='Истинные значения ряда')\n",
    "plt.plot(X_retail_test.index, ..., marker='.', c='red', label='Прогноз ряда с помощью tree_retail')\n",
    "plt.plot(X_retail_test.index, ..., marker='.', c='green', label='Прогноз ряда с помощью tree_retail_diff')\n",
    "plt.xlabel('Время')\n",
    "plt.ylabel('Объём продаж, млн. долл. США')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "204px",
    "width": "380px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
